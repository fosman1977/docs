---
title: "Redis Caching"
description: "Distributed caching with Redis for performance optimization"
---

# Redis Caching

The Chambers Platform uses Redis for distributed caching to improve performance and reduce database load.

## Overview

| Feature | Details |
|---------|---------|
| **Provider** | Redis (Upstash) |
| **Purpose** | Session storage, API caching, rate limiting |
| **Direction** | Internal |

## Use Cases

### Session Storage

User sessions are stored in Redis for:
- Distributed session management
- Fast session lookups
- Automatic expiry

### API Response Caching

Frequently accessed data is cached:
- AI insights (24 hour TTL)
- Dashboard statistics (5 minute TTL)
- Barrister availability (30 minute TTL)

### Rate Limiting

Request rate limiting per:
- User ID
- IP address
- API endpoint

## Configuration

### Environment Variables

```bash
# Redis connection (Upstash)
UPSTASH_REDIS_REST_URL=https://xxx.upstash.io
UPSTASH_REDIS_REST_TOKEN=xxx

# Optional: Connection pooling
REDIS_MAX_CONNECTIONS=10
REDIS_CONNECTION_TIMEOUT=5000
```

## Cache Service

### Basic Usage

```typescript
// src/lib/cache/redis.ts
import { Redis } from '@upstash/redis';

const redis = new Redis({
  url: process.env.UPSTASH_REDIS_REST_URL,
  token: process.env.UPSTASH_REDIS_REST_TOKEN,
});

export async function cacheGet<T>(key: string): Promise<T | null> {
  return await redis.get<T>(key);
}

export async function cacheSet(
  key: string,
  value: any,
  ttlSeconds: number
): Promise<void> {
  await redis.set(key, value, { ex: ttlSeconds });
}

export async function cacheDelete(key: string): Promise<void> {
  await redis.del(key);
}
```

### Cache Key Patterns

| Pattern | Example | Purpose |
|---------|---------|---------|
| `session:{id}` | `session:abc123` | User sessions |
| `insights:{year}` | `insights:2024` | Cached AI insights |
| `stats:{type}:{period}` | `stats:leads:daily` | Dashboard statistics |
| `availability:{id}` | `availability:user123` | Barrister availability |
| `rate:{endpoint}:{id}` | `rate:/api/ai:user123` | Rate limiting counters |

## Cache Strategies

### Cache-Aside (Lazy Loading)

```typescript
async function getBarristerStats(barristerId: string) {
  const cacheKey = `stats:barrister:${barristerId}`;

  // Try cache first
  const cached = await cacheGet<BarristerStats>(cacheKey);
  if (cached) {
    return cached;
  }

  // Fetch from database
  const stats = await db.query.barristers.findFirst({
    where: eq(barristers.id, barristerId)
  });

  // Store in cache with 5 minute TTL
  await cacheSet(cacheKey, stats, 300);

  return stats;
}
```

### Write-Through

```typescript
async function updateBarristerProfile(barristerId: string, data: any) {
  // Update database
  await db.update(barristers)
    .set(data)
    .where(eq(barristers.id, barristerId));

  // Invalidate cache
  await cacheDelete(`stats:barrister:${barristerId}`);
  await cacheDelete(`availability:${barristerId}`);
}
```

### Cache Warming

```typescript
// Warm cache on server start
async function warmCache() {
  // Pre-cache frequently accessed data
  const allBarristers = await db.query.barristers.findMany();

  for (const barrister of allBarristers) {
    const stats = calculateStats(barrister);
    await cacheSet(`stats:barrister:${barrister.id}`, stats, 3600);
  }
}
```

## TTL Configuration

| Data Type | TTL | Reason |
|-----------|-----|--------|
| Sessions | 24 hours | Security balance |
| AI Insights | 24 hours | Expensive to regenerate |
| Dashboard stats | 5 minutes | Balance freshness vs load |
| Availability | 30 minutes | Availability data updates |
| Rate limit counters | 1 minute | Rolling window |

## Rate Limiting

### Implementation

```typescript
import { Ratelimit } from '@upstash/ratelimit';
import { Redis } from '@upstash/redis';

const redis = new Redis({
  url: process.env.UPSTASH_REDIS_REST_URL,
  token: process.env.UPSTASH_REDIS_REST_TOKEN,
});

const ratelimit = new Ratelimit({
  redis,
  limiter: Ratelimit.slidingWindow(10, '10 s'), // 10 requests per 10 seconds
  analytics: true
});

export async function checkRateLimit(identifier: string) {
  const { success, limit, remaining, reset } = await ratelimit.limit(identifier);

  return {
    allowed: success,
    limit,
    remaining,
    resetAt: new Date(reset)
  };
}
```

### Rate Limits by Endpoint

| Endpoint | Limit | Window |
|----------|-------|--------|
| `/api/ai/*` | 10 requests | 1 minute |
| `/api/leads` | 100 requests | 1 minute |
| `/api/auth/*` | 5 requests | 1 minute |
| General API | 1000 requests | 1 minute |

## Error Handling

### Connection Failures

```typescript
async function safeCacheGet<T>(key: string, fallback: T): Promise<T> {
  try {
    const cached = await cacheGet<T>(key);
    return cached ?? fallback;
  } catch (error) {
    console.error('Redis error:', error);
    // Return fallback, don't crash the app
    return fallback;
  }
}
```

### Circuit Breaker

```typescript
let cacheAvailable = true;
let lastError = 0;
const CIRCUIT_TIMEOUT = 30000; // 30 seconds

async function cacheWithCircuitBreaker<T>(
  key: string,
  fallbackFn: () => Promise<T>
): Promise<T> {
  // Check if circuit is open
  if (!cacheAvailable) {
    if (Date.now() - lastError > CIRCUIT_TIMEOUT) {
      cacheAvailable = true; // Try again
    } else {
      return fallbackFn();
    }
  }

  try {
    const cached = await cacheGet<T>(key);
    if (cached) return cached;

    const value = await fallbackFn();
    await cacheSet(key, value, 300);
    return value;
  } catch (error) {
    cacheAvailable = false;
    lastError = Date.now();
    return fallbackFn();
  }
}
```

## Monitoring

### Cache Hit Rate

```typescript
let hits = 0;
let misses = 0;

export function getCacheStats() {
  const total = hits + misses;
  return {
    hits,
    misses,
    hitRate: total > 0 ? (hits / total) * 100 : 0
  };
}
```

### Memory Usage

Monitor at Upstash dashboard:
- Used memory
- Key count
- Operations per second
- Network bandwidth

## Troubleshooting

### Cache Misses

1. **Check TTL** - May be too short
2. **Check key format** - Case-sensitive
3. **Check serialization** - Complex objects may fail
4. **Check connection** - Upstash endpoint accessible

### Stale Data

1. **Implement cache invalidation** - On updates
2. **Use shorter TTL** - For volatile data
3. **Add version prefix** - To force refresh

### Memory Issues

1. **Monitor key count** - At Upstash dashboard
2. **Review TTL settings** - Reduce for large values
3. **Implement eviction** - LRU for bounded caches

## Best Practices

### Key Naming

```typescript
// Good: Descriptive, hierarchical
const key = `insights:chambers:${year}:${quarter}`;

// Bad: Ambiguous, flat
const key = `data_${id}`;
```

### Serialization

```typescript
// Cache complex objects as JSON
await cacheSet(key, JSON.stringify(complexObject), ttl);
const value = JSON.parse(await cacheGet(key) || '{}');
```

### Atomic Operations

```typescript
// Use Redis transactions for consistency
const pipeline = redis.pipeline();
pipeline.set('key1', 'value1');
pipeline.set('key2', 'value2');
await pipeline.exec();
```

## Security

- **Never cache sensitive PII** directly
- **Hash or tokenize** identifiers in keys
- **Use TLS** for Upstash connections (automatic)
- **Rotate tokens** periodically
